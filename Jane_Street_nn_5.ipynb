{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3Idt8QOwmIK",
        "outputId": "e3cc216d-c0f8-463f-84c8-9022f4486efe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w30tW-FrEVsK"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "def install_packages(packages):\n",
        "    \"\"\"\n",
        "    Install a list of packages using pip.\n",
        "\n",
        "    Args:\n",
        "        packages (list): A list of package names to install.\n",
        "    \"\"\"\n",
        "    for package in packages:\n",
        "        subprocess.run([\"pip\", \"install\", package], check=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L8DydRgCEdKj"
      },
      "outputs": [],
      "source": [
        "packages_to_install = [\"keras_hub\", \"polars\"]\n",
        "\n",
        "# Install the packages\n",
        "install_packages(packages_to_install)\n",
        "\n",
        "# Core data processing and numerical libraries\n",
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Keras imports\n",
        "from keras import layers\n",
        "from keras import Model\n",
        "from keras import ops\n",
        "from keras_hub.layers import TransformerEncoder\n",
        "from keras import regularizers\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "from pathlib import Path\n",
        "import gc\n",
        "\n",
        "DATA_DIR = Path(\"/content/drive/MyDrive/Colab Notebooks/Jane_Street/data/train.parquet/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6h64l6DJytys"
      },
      "outputs": [],
      "source": [
        "feature_09_dict = {\n",
        "    2: 0,\n",
        "    4: 1,\n",
        "    9: 2,\n",
        "    11: 3,\n",
        "    12: 4,\n",
        "    14: 5,\n",
        "    15: 6,\n",
        "    25: 7,\n",
        "    26: 8,\n",
        "    30: 9,\n",
        "    34: 10,\n",
        "    42: 11,\n",
        "    44: 12,\n",
        "    46: 13,\n",
        "    49: 14,\n",
        "    50: 15,\n",
        "    57: 16,\n",
        "    64: 17,\n",
        "    68: 18,\n",
        "    70: 19,\n",
        "    81: 20,\n",
        "    82: 21\n",
        "}\n",
        "feature_10_dict = {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 10: 7, 12: 8}\n",
        "feature_11_dict = {\n",
        "    9: 0,\n",
        "    11: 1,\n",
        "    13: 2,\n",
        "    16: 3,\n",
        "    24: 4,\n",
        "    25: 5,\n",
        "    34: 6,\n",
        "    40: 7,\n",
        "    48: 8,\n",
        "    50: 9,\n",
        "    59: 10,\n",
        "    62: 11,\n",
        "    63: 12,\n",
        "    66: 13,\n",
        "    76: 14,\n",
        "    150: 15,\n",
        "    158: 16,\n",
        "    159: 17,\n",
        "    171: 18,\n",
        "    195: 19,\n",
        "    214: 20,\n",
        "    230: 21,\n",
        "    261: 22,\n",
        "    297: 23,\n",
        "    336: 24,\n",
        "    376: 25,\n",
        "    388: 26,\n",
        "    410: 27,\n",
        "    522: 28,\n",
        "    534: 29,\n",
        "    539: 30\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(1000, 64))\n",
        "# The model will take as input an integer matrix of size (batch,\n",
        "# input_length), and the largest integer (i.e. word index) in the input\n",
        "# should be no larger than 999 (vocabulary size).\n",
        "# Now model.output_shape is (None, 10, 64), where `None` is the batch\n",
        "# dimension.\n",
        "input_array = np.random.randint(10, size=(5))\n",
        "model.compile('rmsprop', 'mse')\n",
        "output_array = model.predict(input_array)\n",
        "print(output_array.shape)\n",
        "(32, 10, 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrE-j-Uz8G2R",
        "outputId": "4c467b73-1182-49bf-d1e2-b529e2873d72"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "(5, 64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 10, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4oO5Ey_8-9s",
        "outputId": "a148d081-87d3-4002-f10d-c3e0cf0b2b99"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OlZMFgl8_Ax",
        "outputId": "0ecf4956-3f8a-4559-96a7-672e76638e50"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bszB3z858_EJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "F4WSz2BIyt1y"
      },
      "outputs": [],
      "source": [
        "def reduce_memory_usage() -> pl.Expr:\n",
        "    expressions = [\n",
        "        pl.col(pl.Float64).cast(pl.Float32),\n",
        "        pl.col(\"date_id\", \"time_id\").cast(pl.Int16),\n",
        "        pl.col(\"symbol_id\").cast(pl.Int8),\n",
        "        ]\n",
        "    return expressions\n",
        "\n",
        "def get_lag_responders() -> pl.Expr:\n",
        "    cols = [f\"responder_{i}\" for i in range(9)]\n",
        "    expressions = [\n",
        "        pl.col(col)\n",
        "        .shift(i)\n",
        "        .over('symbol_id', 'time_id')\n",
        "        .alias(f\"{col}_lag_{i}\")\n",
        "        for col in cols for i in [1] # lags\n",
        "        ]\n",
        "    return expressions\n",
        "\n",
        "def map_category() -> pl.Expr:\n",
        "    expressions = [\n",
        "        pl.col('symbol_id').replace({i: i for i in range(39)}).fill_null(99),\n",
        "        pl.col('feature_09').replace(feature_09_dict).fill_null(99),\n",
        "        pl.col('feature_10').replace(feature_10_dict).fill_null(99),\n",
        "        pl.col('feature_11').replace(feature_11_dict).fill_null(99),\n",
        "    ]\n",
        "    return expressions\n",
        "\n",
        "def get_temporal_features() -> pl.Expr:\n",
        "    expressions = [\n",
        "        (pl.col('date_id') % 170).alias('day'),\n",
        "        (pl.col('date_id') * 2 * np.pi / 170).sin().cast(pl.Float32).alias('date_sin'),\n",
        "        (pl.col('date_id') * 2 * np.pi / 170).cos().cast(pl.Float32).alias('date_cos'),\n",
        "        # (pl.col('time_id') * 2 * np.pi / 967).sin().cast(pl.Float32).alias('time_id_sin'),\n",
        "        # (pl.col('time_id') * 2 * np.pi / 967).cos().cast(pl.Float32).alias('time_id_cos')\n",
        "    ]\n",
        "    return expressions\n",
        "\n",
        "def get_lag_stats_per_day() -> pl.Expr:\n",
        "    group = [\"date_id\", \"symbol_id\"]\n",
        "    # cols = [f\"responder_{i}_lag_1\" for i in range(9)]\n",
        "    cols = ['responder_6_lag_1']\n",
        "    expressions = []\n",
        "    for col in cols:\n",
        "        exprs = [\n",
        "            # pl.col(col).min().over(group).alias(f\"{col}_min\"),\n",
        "            pl.col(col).max().over(group).alias(f\"{col}_max\"),\n",
        "            # pl.col(col).std().over(group).alias(f\"{col}_std\")\n",
        "            # pl.col(col).median().over(group).alias(f\"{col}_median_per_day\")\n",
        "        ]\n",
        "        expressions.extend(exprs)\n",
        "    return expressions\n",
        "\n",
        "def get_lag_features() -> pl.Expr:\n",
        "    group = ['symbol_id', 'date_id']\n",
        "    expressions = [\n",
        "        pl.col('feature_07').shift(2).over(group).alias('feature_07_lag'),\n",
        "        pl.col('feature_06').shift(1).over(group).alias('feature_06_lag'),\n",
        "        pl.col('feature_60').shift(2).over(group).alias('feature_60_lag'),\n",
        "        # pl.col('feature_04').shift(4).over(group).alias('feature_04_lag'),\n",
        "        # pl.col('feature_05').shift(5).over(group).alias('feature_05_lag'),\n",
        "        # pl.col('feature_36').shift(4).over(group).alias('feature_36_lag'),\n",
        "        # pl.col('feature_58').shift(4).over(group).alias('feature_58_lag'),\n",
        "        # pl.col('feature_59').shift(1).over(group).alias('feature_59_lag'),\n",
        "        # pl.col('feature_38').shift(8).over(group).alias('feature_38_lag'),\n",
        "        # pl.col('feature_52').shift(3).over(group).alias('feature_52_lag'),\n",
        "    ]\n",
        "    return expressions\n",
        "\n",
        "def get_tag_means() -> pl.Expr:\n",
        "    expressions = [\n",
        "        pl.mean_horizontal(tag_11_cols).alias('tag_11_mean'),\n",
        "    ]\n",
        "    return expressions\n",
        "\n",
        "def generate_features(df):\n",
        "    exprs_1 = [\n",
        "        map_category(),\n",
        "        get_temporal_features(),\n",
        "        get_lag_features(),\n",
        "        get_tag_means(),\n",
        "        get_lag_responders(),\n",
        "    ]\n",
        "    expressions = [e for sublist in exprs_1 for e in sublist]\n",
        "    df = df.with_columns(reduce_memory_usage())\n",
        "    df = df.with_columns(\n",
        "        pl.col('feature_09').cast(pl.Int8),\n",
        "        pl.col('feature_10').cast(pl.Int8),\n",
        "        pl.col('feature_11').cast(pl.Int16),\n",
        "    )\n",
        "    df = df.with_columns(expressions)\n",
        "    df = df.with_columns(get_lag_stats_per_day())\n",
        "\n",
        "    df = df.with_columns(\n",
        "        pl.col('time_id') / 968,\n",
        "        pl.col('day') / 170\n",
        "    )\n",
        "\n",
        "    ign_cols = [f\"responder_{i}_lag_1\" for i in range(9)]\n",
        "    return df.select(pl.all().exclude(ign_cols))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6BKi3ucFzpRX"
      },
      "outputs": [],
      "source": [
        "df_feat = pl.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Jane_Street/data/features.csv\")\n",
        "tag_11_cols = df_feat.filter(pl.col('tag_11')==True)['feature'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "XJwxQQRLyt5L",
        "outputId": "a9e907b0-19b4-4d79-d63b-6b37dc986e4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (5, 101)\n",
              "┌─────────┬─────────┬───────────┬──────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
              "│ date_id ┆ time_id ┆ symbol_id ┆ weight   ┆ … ┆ feature_06 ┆ feature_60 ┆ tag_11_mea ┆ responder_ │\n",
              "│ ---     ┆ ---     ┆ ---       ┆ ---      ┆   ┆ _lag       ┆ _lag       ┆ n          ┆ 6_lag_1_ma │\n",
              "│ i16     ┆ f64     ┆ i8        ┆ f32      ┆   ┆ ---        ┆ ---        ┆ ---        ┆ x          │\n",
              "│         ┆         ┆           ┆          ┆   ┆ f32        ┆ f32        ┆ f64        ┆ ---        │\n",
              "│         ┆         ┆           ┆          ┆   ┆            ┆            ┆            ┆ f32        │\n",
              "╞═════════╪═════════╪═══════════╪══════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
              "│ 1021    ┆ 0.0     ┆ 0         ┆ 2.758212 ┆ … ┆ 0.0        ┆ 0.0        ┆ 0.201346   ┆ 3.252243   │\n",
              "│ 1021    ┆ 0.0     ┆ 1         ┆ 5.128181 ┆ … ┆ 0.0        ┆ 0.0        ┆ -0.110867  ┆ 4.152138   │\n",
              "│ 1021    ┆ 0.0     ┆ 2         ┆ 2.990457 ┆ … ┆ 0.0        ┆ 0.0        ┆ 1.525596   ┆ 5.0        │\n",
              "│ 1021    ┆ 0.0     ┆ 3         ┆ 1.580349 ┆ … ┆ 0.0        ┆ 0.0        ┆ 0.013414   ┆ 3.490906   │\n",
              "│ 1021    ┆ 0.0     ┆ 4         ┆ 3.252043 ┆ … ┆ 0.0        ┆ 0.0        ┆ 0.939671   ┆ 5.0        │\n",
              "└─────────┴─────────┴───────────┴──────────┴───┴────────────┴────────────┴────────────┴────────────┘"
            ],
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr,\n",
              ".dataframe > tbody > tr {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (5, 101)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date_id</th><th>time_id</th><th>symbol_id</th><th>weight</th><th>feature_00</th><th>feature_01</th><th>feature_02</th><th>feature_03</th><th>feature_04</th><th>feature_05</th><th>feature_06</th><th>feature_07</th><th>feature_08</th><th>feature_09</th><th>feature_10</th><th>feature_11</th><th>feature_12</th><th>feature_13</th><th>feature_14</th><th>feature_15</th><th>feature_16</th><th>feature_17</th><th>feature_18</th><th>feature_19</th><th>feature_20</th><th>feature_21</th><th>feature_22</th><th>feature_23</th><th>feature_24</th><th>feature_25</th><th>feature_26</th><th>feature_27</th><th>feature_28</th><th>feature_29</th><th>feature_30</th><th>feature_31</th><th>feature_32</th><th>&hellip;</th><th>feature_60</th><th>feature_61</th><th>feature_62</th><th>feature_63</th><th>feature_64</th><th>feature_65</th><th>feature_66</th><th>feature_67</th><th>feature_68</th><th>feature_69</th><th>feature_70</th><th>feature_71</th><th>feature_72</th><th>feature_73</th><th>feature_74</th><th>feature_75</th><th>feature_76</th><th>feature_77</th><th>feature_78</th><th>responder_0</th><th>responder_1</th><th>responder_2</th><th>responder_3</th><th>responder_4</th><th>responder_5</th><th>responder_6</th><th>responder_7</th><th>responder_8</th><th>partition_id</th><th>day</th><th>date_sin</th><th>date_cos</th><th>feature_07_lag</th><th>feature_06_lag</th><th>feature_60_lag</th><th>tag_11_mean</th><th>responder_6_lag_1_max</th></tr><tr><td>i16</td><td>f64</td><td>i8</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>i8</td><td>i8</td><td>i16</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>i64</td><td>f64</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f64</td><td>f32</td></tr></thead><tbody><tr><td>1021</td><td>0.0</td><td>0</td><td>2.758212</td><td>-0.88871</td><td>-0.280876</td><td>-0.709766</td><td>-1.114013</td><td>2.130691</td><td>-0.675838</td><td>-0.217391</td><td>-0.15832</td><td>0.157831</td><td>3</td><td>6</td><td>14</td><td>-0.824303</td><td>1.321677</td><td>-0.211726</td><td>0.0</td><td>0.028558</td><td>0.0</td><td>-1.903073</td><td>-1.309708</td><td>0.56428</td><td>-0.113246</td><td>0.460829</td><td>0.874078</td><td>-0.634349</td><td>-0.989553</td><td>0.363487</td><td>1.548323</td><td>0.658012</td><td>-0.147794</td><td>-0.0248</td><td>-0.11404</td><td>0.0</td><td>&hellip;</td><td>-0.031517</td><td>0.822857</td><td>-0.120644</td><td>-0.096939</td><td>-0.165281</td><td>-1.85763</td><td>-1.983462</td><td>-0.761288</td><td>1.461293</td><td>-0.095967</td><td>-0.949327</td><td>0.945887</td><td>-0.22943</td><td>0.0</td><td>0.0</td><td>-0.086589</td><td>-0.138892</td><td>-0.339265</td><td>-0.208284</td><td>0.143218</td><td>0.036284</td><td>0.605471</td><td>-2.160379</td><td>-2.312699</td><td>-1.693053</td><td>-3.237157</td><td>-2.757349</td><td>-2.678967</td><td>6</td><td>0.005882</td><td>0.036952</td><td>0.999317</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.201346</td><td>3.252243</td></tr><tr><td>1021</td><td>0.0</td><td>1</td><td>5.128181</td><td>-0.667143</td><td>-0.156818</td><td>-0.551448</td><td>-1.022433</td><td>1.902604</td><td>-0.591912</td><td>-0.243567</td><td>-0.178642</td><td>0.154012</td><td>3</td><td>6</td><td>14</td><td>-1.341635</td><td>0.35188</td><td>-0.521197</td><td>0.0</td><td>-0.344777</td><td>0.0</td><td>-1.983181</td><td>-1.479607</td><td>0.43023</td><td>0.102232</td><td>1.243619</td><td>1.429466</td><td>-0.268186</td><td>-0.352289</td><td>0.443074</td><td>1.538062</td><td>1.902193</td><td>-0.358995</td><td>-0.486083</td><td>0.120412</td><td>0.0</td><td>&hellip;</td><td>-0.110262</td><td>0.822857</td><td>-0.224284</td><td>-0.379963</td><td>-0.184559</td><td>-1.470559</td><td>-1.480629</td><td>-0.691343</td><td>0.60478</td><td>-0.246037</td><td>-1.084746</td><td>-0.031681</td><td>-0.598442</td><td>0.0</td><td>0.0</td><td>-0.292409</td><td>-0.29329</td><td>-0.189932</td><td>-0.304927</td><td>0.080642</td><td>0.031724</td><td>0.098682</td><td>-0.183446</td><td>-0.492214</td><td>0.865066</td><td>-0.417081</td><td>-0.854174</td><td>1.2233</td><td>6</td><td>0.005882</td><td>0.036952</td><td>0.999317</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-0.110867</td><td>4.152138</td></tr><tr><td>1021</td><td>0.0</td><td>2</td><td>2.990457</td><td>-0.592874</td><td>-0.843829</td><td>-1.172633</td><td>-0.977152</td><td>1.665111</td><td>-0.780339</td><td>-0.248836</td><td>-0.295433</td><td>0.212535</td><td>20</td><td>1</td><td>10</td><td>-0.68717</td><td>4.194336</td><td>0.333165</td><td>0.0</td><td>-0.048717</td><td>0.0</td><td>-2.749262</td><td>-1.98124</td><td>-0.741161</td><td>-0.110016</td><td>0.762164</td><td>0.384524</td><td>-1.003869</td><td>-0.887358</td><td>0.924972</td><td>1.867121</td><td>1.078736</td><td>-0.892071</td><td>-0.564501</td><td>-0.161899</td><td>0.0</td><td>&hellip;</td><td>3.020605</td><td>0.822857</td><td>-0.163303</td><td>-0.217823</td><td>-0.203042</td><td>-1.729299</td><td>-1.913308</td><td>-0.555369</td><td>4.493433</td><td>0.638722</td><td>-0.765278</td><td>2.414558</td><td>-0.003537</td><td>0.0</td><td>0.0</td><td>0.36877</td><td>0.558933</td><td>-0.099664</td><td>-0.018457</td><td>0.105283</td><td>0.214745</td><td>0.353996</td><td>-1.960483</td><td>-1.242982</td><td>-2.430258</td><td>-3.529213</td><td>-2.412281</td><td>-3.481411</td><td>6</td><td>0.005882</td><td>0.036952</td><td>0.999317</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1.525596</td><td>5.0</td></tr><tr><td>1021</td><td>0.0</td><td>3</td><td>1.580349</td><td>-0.949817</td><td>-0.223031</td><td>-0.797525</td><td>-0.895173</td><td>2.020643</td><td>-0.434421</td><td>-0.165368</td><td>-0.207286</td><td>0.163731</td><td>1</td><td>2</td><td>1</td><td>-0.966018</td><td>1.740896</td><td>-0.26865</td><td>0.0</td><td>-0.274083</td><td>0.0</td><td>-0.462178</td><td>-1.663668</td><td>-0.468623</td><td>-0.010726</td><td>-0.718504</td><td>-0.659684</td><td>0.657763</td><td>0.178212</td><td>-0.276047</td><td>-1.019963</td><td>-0.891104</td><td>-0.443206</td><td>-0.595868</td><td>-0.0089</td><td>0.0</td><td>&hellip;</td><td>0.785277</td><td>0.822857</td><td>-0.211538</td><td>-0.221234</td><td>-0.141883</td><td>-1.854496</td><td>-1.293521</td><td>-0.906615</td><td>1.082458</td><td>-0.1356</td><td>-0.96185</td><td>1.193984</td><td>-0.453</td><td>0.0</td><td>0.0</td><td>1.113736</td><td>1.278999</td><td>0.051255</td><td>0.033749</td><td>0.078974</td><td>0.088442</td><td>0.710223</td><td>1.622804</td><td>2.530923</td><td>1.304712</td><td>2.790201</td><td>2.580255</td><td>1.266655</td><td>6</td><td>0.005882</td><td>0.036952</td><td>0.999317</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.013414</td><td>3.490906</td></tr><tr><td>1021</td><td>0.0</td><td>4</td><td>3.252043</td><td>-0.611066</td><td>-0.523858</td><td>-0.769166</td><td>-1.01305</td><td>1.424418</td><td>-0.265226</td><td>-0.093243</td><td>-0.09816</td><td>0.076199</td><td>6</td><td>0</td><td>0</td><td>-0.771626</td><td>4.367999</td><td>0.230222</td><td>0.0</td><td>-0.341415</td><td>0.0</td><td>-1.277562</td><td>-1.053409</td><td>-0.160347</td><td>0.884322</td><td>0.977945</td><td>-0.11547</td><td>2.352565</td><td>2.582544</td><td>-1.674891</td><td>-0.515939</td><td>0.555117</td><td>-0.733854</td><td>-1.190635</td><td>0.581692</td><td>0.0</td><td>&hellip;</td><td>1.005107</td><td>0.822857</td><td>-0.216605</td><td>-0.376726</td><td>-0.490268</td><td>-2.035804</td><td>-2.006988</td><td>-0.55399</td><td>3.02505</td><td>0.347953</td><td>-0.657172</td><td>2.611223</td><td>-0.002669</td><td>0.0</td><td>0.0</td><td>8.576644</td><td>8.451904</td><td>9.772758</td><td>6.689439</td><td>-1.08646</td><td>-0.860899</td><td>-2.133953</td><td>1.432439</td><td>-2.483309</td><td>-1.849198</td><td>3.356596</td><td>-2.83107</td><td>-3.252782</td><td>6</td><td>0.005882</td><td>0.036952</td><td>0.999317</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.939671</td><td>5.0</td></tr></tbody></table></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train = pl.scan_parquet(DATA_DIR).filter(pl.col('partition_id')>5)\n",
        "train = generate_features(train)\n",
        "# remove nulls resulting from day 1 lags\n",
        "start_date = train.select(pl.first('date_id')).collect()\n",
        "train = train.filter(pl.col('date_id') > start_date)\n",
        "train = train.fill_null(0)\n",
        "\n",
        "train.head(5).collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def min_max_scaler(df: pl.DataFrame, columns: List) -> pl.DataFrame:\n",
        "    for col in columns:\n",
        "        col_min = df[col].min()\n",
        "        col_max = df[col].max()\n",
        "        df = df.with_columns(\n",
        "            ((pl.col(col) - col_min) / ((col_max - col_min)+1e-10)).alias(col)\n",
        "            )\n",
        "    return df"
      ],
      "metadata": {
        "id": "cJu_e1HEbQxc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temporal_features = ['day', 'date_sin', 'date_cos', 'time_id']\n",
        "features = [f\"feature_{i:02}\" for i in range(79)]\n",
        "cat_features = ['feature_09', 'feature_10', 'feature_11']\n",
        "lag_features = [f\"responder_{i}_lag_1\" for i in range(9)]\n",
        "other_features = ['weight',\n",
        "                  'feature_07_lag',\n",
        "                  'feature_06_lag',\n",
        "                  'feature_60_lag',\n",
        "                  'tag_11_mean',\n",
        "                  'responder_6_lag_1_max'\n",
        "                  ]\n",
        "trend_features = features + other_features\n",
        "trend_features = [x for x in trend_features if x not in cat_features]\n",
        "targets = ['responder_6']\n",
        "\n",
        "df_train = train.filter(pl.col('date_id')<1576).select(\n",
        "    temporal_features+trend_features+targets+['date_id', 'symbol_id']\n",
        "    ).collect()\n",
        "df_train = min_max_scaler(df_train, temporal_features + trend_features)\n",
        "\n",
        "df_valid = train.filter(pl.col('date_id')>1576).select(\n",
        "    temporal_features+trend_features+targets+['date_id', 'symbol_id']\n",
        "    ).collect()\n",
        "df_valid = min_max_scaler(df_valid, temporal_features + trend_features)"
      ],
      "metadata": {
        "id": "d4hwmNnBifEy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sequences(df, seq_length=8, stride=8):\n",
        "    data = df.to_numpy()\n",
        "    num_sequences = (len(data) - seq_length) // stride + 1\n",
        "    sequences = np.zeros((num_sequences, seq_length, df.shape[1]))\n",
        "    for i in range(num_sequences):\n",
        "        start_idx = i * stride\n",
        "        end_idx = start_idx + seq_length\n",
        "        sequences[i, :, :] = data[start_idx:end_idx]\n",
        "    return sequences"
      ],
      "metadata": {
        "id": "WDZxHbniWH0R"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, df: pl.DataFrame, sequence_length=8, stride=8):\n",
        "        self.df = df\n",
        "        self.date_ids = df['date_id'].unique().to_list()\n",
        "        self.sequence_length = sequence_length\n",
        "        self.stride = stride\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.date_ids)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        date_id = self.date_ids[index]\n",
        "        df_ = self.df.filter(pl.col('date_id') == date_id)\n",
        "\n",
        "        temporal_data = []\n",
        "        trend_data = []\n",
        "        target_data = []\n",
        "\n",
        "        for _, data in df_.group_by('symbol_id'):\n",
        "            temporal_data.append(\n",
        "                get_sequences(\n",
        "                    data.select(temporal_features)[:-self.sequence_length],\n",
        "                    seq_length=self.sequence_length,\n",
        "                    stride=self.stride\n",
        "                    )\n",
        "            )\n",
        "            trend_data.append(\n",
        "                get_sequences(\n",
        "                    data.select(trend_features)[:-self.sequence_length],\n",
        "                    seq_length=self.sequence_length,\n",
        "                    stride=self.stride\n",
        "                    )\n",
        "            )\n",
        "            target_data.append(\n",
        "                get_sequences(\n",
        "                    data.select(targets)[self.sequence_length:],\n",
        "                    seq_length=self.sequence_length,\n",
        "                    stride=self.stride\n",
        "                    )\n",
        "            )\n",
        "\n",
        "        temporal_data = np.vstack(temporal_data)\n",
        "        trend_data = np.vstack(trend_data)\n",
        "        target_data = np.vstack(target_data)\n",
        "\n",
        "        return [temporal_data, trend_data], target_data\n",
        "\n",
        "    @property\n",
        "    def num_batches(self):\n",
        "        return len(self)\n",
        "\n",
        "train_generator = DataGenerator(df_train)\n",
        "valid_generator = DataGenerator(df_valid)"
      ],
      "metadata": {
        "id": "2wW3lTChecUF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for [x1, x2], y in train_generator:\n",
        "  break\n",
        "x2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcjtm-ntlO9j",
        "outputId": "795b1e64-226b-4bab-d729-32334a084372"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4080, 8, 82)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nni3YUW3zkce"
      },
      "outputs": [],
      "source": [
        "# Adapted from\n",
        "# https://keras.io/examples/generative/customer_lifetime_value/\n",
        "keras.config.set_dtype_policy(\"mixed_float16\")\n",
        "\n",
        "def build_model(\n",
        "    input_sequence_length: int,\n",
        "    output_sequence_length: int,\n",
        "    # num_symbols: int,\n",
        "    d_model: int = 8,\n",
        "    num_heads: int = 4,\n",
        "    ):\n",
        "\n",
        "    keras.utils.set_random_seed(seed=42)\n",
        "\n",
        "    # Inputs\n",
        "    temporal_inputs = layers.Input(\n",
        "        shape=(input_sequence_length, 4), name=\"temporal_inputs\"\n",
        "    )\n",
        "    trend_inputs = layers.Input(shape=(input_sequence_length, 82), name=\"trend_inputs\")\n",
        "\n",
        "    symbol_inputs = layers.Input(\n",
        "        shape=(input_sequence_length,), dtype=\"int32\", name=\"symbol_inputs\"\n",
        "    )\n",
        "\n",
        "    # Process symbol features\n",
        "    symbol_embedding = layers.Embedding(\n",
        "        input_dim=40,\n",
        "        output_dim=d_model,\n",
        "        mask_zero=False,\n",
        "        name=\"symbl_embedding\",\n",
        "    )(symbol_inputs)  # Output shape: (batch_size, 1, d_model)\n",
        "\n",
        "    # Flatten the embedding output\n",
        "    symbol_embedding = layers.Flatten(name=\"flatten_symbol_embedding\")(\n",
        "        symbol_embedding\n",
        "    )\n",
        "\n",
        "\n",
        "    temporal_projection = layers.Dense(\n",
        "        d_model, activation=\"tanh\", name=\"temporal_projection\"\n",
        "    )(temporal_inputs)\n",
        "\n",
        "    transformer_output = temporal_projection\n",
        "    for _ in range(2):\n",
        "        transformer_output = TransformerEncoder(\n",
        "            intermediate_dim=16, num_heads=num_heads\n",
        "        )(transformer_output)\n",
        "\n",
        "    lstm_output = layers.LSTM(units=64, name=\"lstm_trend\")(trend_inputs)\n",
        "\n",
        "    transformer_flattened = layers.GlobalAveragePooling1D(name=\"flatten_transformer\")(\n",
        "        transformer_output\n",
        "    )\n",
        "    transformer_flattened = layers.Dense(1, activation=\"sigmoid\")(transformer_flattened)\n",
        "\n",
        "    # Concatenate flattened Transformer output with LSTM output\n",
        "    merged_features = layers.Concatenate(name=\"concatenate_transformer_lstm\")(\n",
        "        [transformer_flattened, lstm_output]\n",
        "    )\n",
        "\n",
        "    # Repeat the merged features to match the output sequence length\n",
        "    decoder_initial = layers.RepeatVector(\n",
        "        output_sequence_length, name=\"repeat_merged_features\"\n",
        "    )(merged_features)\n",
        "\n",
        "    decoder_lstm = layers.LSTM(\n",
        "        units=64,\n",
        "        return_sequences=True,\n",
        "        recurrent_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "    )(decoder_initial)\n",
        "\n",
        "    # Output Dense layer\n",
        "    output = layers.Dense(units=1, activation=\"linear\", name=\"output_dense\")(\n",
        "        decoder_lstm\n",
        "    )\n",
        "\n",
        "    model = Model(\n",
        "        inputs=[temporal_inputs, trend_inputs], outputs=output\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "        loss=\"mse\",\n",
        "        metrics=[\"mae\"],\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "lL0Em5vpzlAA",
        "outputId": "bcd4ca53-4696-42f2-b9b7-82a15413506d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ temporal_inputs           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m4\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cast (\u001b[38;5;33mCast\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m4\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ temporal_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ temporal_projection       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │             \u001b[38;5;34m40\u001b[0m │ cast[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)                   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │            \u001b[38;5;34m600\u001b[0m │ temporal_projection[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │            \u001b[38;5;34m600\u001b[0m │ transformer_encoder[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ trend_inputs (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m82\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_transformer       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ transformer_encoder_1… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cast_1 (\u001b[38;5;33mCast\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m82\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ trend_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m9\u001b[0m │ flatten_transformer[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_trend (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m37,632\u001b[0m │ cast_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_transformer_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ lstm_trend[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ repeat_merged_features    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m65\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ concatenate_transform… │\n",
              "│ (\u001b[38;5;33mRepeatVector\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │         \u001b[38;5;34m33,280\u001b[0m │ repeat_merged_feature… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ output_dense (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │             \u001b[38;5;34m65\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ temporal_inputs           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cast (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ temporal_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ temporal_projection       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │ cast[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │ temporal_projection[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │ transformer_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ trend_inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_transformer       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_encoder_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cast_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ trend_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │ flatten_transformer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_trend (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">37,632</span> │ cast_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_transformer_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ lstm_trend[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ repeat_merged_features    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_transform… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33,280</span> │ repeat_merged_feature… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ output_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m72,226\u001b[0m (282.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">72,226</span> (282.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m72,226\u001b[0m (282.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">72,226</span> (282.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = build_model(\n",
        "    input_sequence_length=8,\n",
        "    output_sequence_length=8,\n",
        "    # num_symbols: int,\n",
        "    d_model=8,\n",
        "    num_heads=4,\n",
        "    )\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qSXPuRkGzlF3"
      },
      "outputs": [],
      "source": [
        "# keras.utils.plot_model(model, \"my_first_model_with_shape_info.png\", show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eMDWHqlQsBZ",
        "outputId": "a89857a8-cd35-444e-ac19-c263d5d86536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m554/555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - loss: 0.7707 - mae: 0.5599"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m555/555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 283ms/step - loss: 0.7705 - mae: 0.5599 - val_loss: 0.6456 - val_mae: 0.5347\n",
            "Epoch 2/10\n",
            "\u001b[1m555/555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 131ms/step - loss: 0.7145 - mae: 0.5444 - val_loss: 0.6445 - val_mae: 0.5351\n",
            "Epoch 3/10\n",
            "\u001b[1m555/555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 126ms/step - loss: 0.7080 - mae: 0.5435 - val_loss: 0.6437 - val_mae: 0.5340\n",
            "Epoch 4/10\n",
            "\u001b[1m555/555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 129ms/step - loss: 0.6988 - mae: 0.5401 - val_loss: 0.6448 - val_mae: 0.5366\n",
            "Epoch 5/10\n",
            "\u001b[1m555/555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 133ms/step - loss: 0.7087 - mae: 0.5435 - val_loss: 0.6436 - val_mae: 0.5345\n",
            "Epoch 6/10\n",
            "\u001b[1m555/555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 134ms/step - loss: 0.7071 - mae: 0.5422 - val_loss: 0.6436 - val_mae: 0.5342\n",
            "Epoch 7/10\n",
            "\u001b[1m555/555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 134ms/step - loss: 0.6908 - mae: 0.5364 - val_loss: 0.6437 - val_mae: 0.5348\n",
            "Epoch 8/10\n",
            "\u001b[1m555/555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 132ms/step - loss: 0.7096 - mae: 0.5408 - val_loss: 0.6436 - val_mae: 0.5337\n",
            "Epoch 9/10\n",
            "\u001b[1m555/555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 132ms/step - loss: 0.7361 - mae: 0.5534 - val_loss: 0.6431 - val_mae: 0.5344\n",
            "Epoch 10/10\n",
            "\u001b[1m555/555\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 129ms/step - loss: 0.7085 - mae: 0.5426 - val_loss: 0.6428 - val_mae: 0.5349\n",
            "CPU times: user 23min 18s, sys: 3min 53s, total: 27min 11s\n",
            "Wall time: 13min 48s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "callback = keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=3, restore_best_weights=True\n",
        "        )\n",
        "\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        epochs=10,\n",
        "        validation_data=(\n",
        "            valid_generator\n",
        "            ),\n",
        "        callbacks=[callback],\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model_nn5.keras\")"
      ],
      "metadata": {
        "id": "AWUyRL4ml81z"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(valid_generator).reshape(-1)"
      ],
      "metadata": {
        "id": "obm_-o9woqWt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2335bff1-9880-438a-ef0f-346673809930"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 109ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NKxzj6tmw_e",
        "outputId": "aced7408-edd3-418d-e86a-b549e5228da0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.303"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0FSSkuSmzMG",
        "outputId": "2b86ecb8-49cd-423e-b019-13f51f5039d7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.355"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "start = 0\n",
        "for i in range(len(valid_generator)):\n",
        "    y_true = valid_generator[i][1].reshape(-1)\n",
        "    y_pred = preds[start: start+len(y_true)]\n",
        "    start = start + len(y_true)\n",
        "    scores.append(r2_score(y_true, y_pred))\n",
        "\n",
        "np.array(scores).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSV3yz8LkoPV",
        "outputId": "820a1077-8e57-43c2-9cfb-7185704a6302"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0029407748505858224"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ufub0frbm1Mt"
      },
      "execution_count": 24,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMNK+N0NZoXRNqgQbG6Ued2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}